# Description: Configuration file for Transformer model

# Sentence piece settings
tokenizer:
    UNK_IDX: 0
    BOS_IDX: 1
    EOS_IDX: 2
    PAD_IDX: 3
    SMILES:
        col_name: SMILES
        col_idx: 2
        vocab_size: 128
        algorithm: bpe
    SIGNATURE:
        col_name: SIGNATURE
        col_idx: 3
        vocab_size: 512
        algorithm: bpe
    ECFP:
        col_name: ECFP
        col_idx: 4
        vocab_size: 2048
        algorithm: bpe

# Transformer settings
model:
    dim_model: 512
    num_heads: 8
    num_encoder_layers: 2
    num_decoder_layers: 2
    dropout_rate: 0.1

# Training settings
training:
    batch_size: 8
    max_seq_len: 64
    learning_rate: 0.001
    epochs: 20
    patience: 10
    max_grad_norm: 1.0
    log_interval: 100
    save_interval: 1
    save_dir: ./model
    device: mps
    kfold: 5
    seed: 42

# Data settings
data:
    base_path:
        metanetx: ./data/metanetx
        emolecules: ./data/emolecules
    dataset_file: dataset/db_descriptors.tsv.gz
    spm_dir: spm
    model_dir: models

# Dynmic information changed by scripts
source: SMILES / SIGNATURE / ECFP
target: SMILES / SIGNATURE / ECFP
dataset: metanetx / emolecules
config: ./src/paper/transformer/config.yaml