# Description: Configuration file for Transformer model

# Sentence piece settings
tokenizer:
    UNK_IDX: 0
    BOS_IDX: 1
    EOS_IDX: 2
    PAD_IDX: 3
    SMILES:
        col_name: SMILES
        col_idx: 2
        vocab_size: 128
        algorithm: bpe
    SIGNATURE:
        col_name: SIGNATURE
        col_idx: 3
        vocab_size: 512
        algorithm: bpe
    ECFP:
        col_name: ECFP
        col_idx: 4
        vocab_size: 2048
        algorithm: bpe

# Transformer settings
model:
    dim_model: 512
    num_heads: 8
    num_encoder_layers: 2
    num_decoder_layers: 2
    dropout_rate: 0.1

# Training settings
training:
    batch_size: 512
    learning_rate: 0.001
    epochs: 20
    patience: 10
    max_grad_norm: 1.0
    log_interval: 20
    save_interval: 1
    kfold: 5
    seed: 42

# Data settings
data:
    dataset_file: dataset/db_descriptors.tsv.gz
    spm_dir: spm

# Dynmic information changed by scripts
source: SMILES / SIGNATURE / ECFP
target: SMILES / SIGNATURE / ECFP
dataset: metanetx / emolecules
base_path: ./data/metanetx / ./data/emolecules
model_dir: models / model_v1 / ...
config: ./src/paper/transformer/config.yaml