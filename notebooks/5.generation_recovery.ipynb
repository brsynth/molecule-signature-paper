{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Recovery from the generative model predictions**\n",
    "\n",
    "The notebook has been used to populate Tables 1 (top-100) and 2 of the manuscript. The notebook content shows\n",
    "the operations for the evaluation of the generative model from eMolecules datasets. Similar operations can be\n",
    "performed for the MetaNetX dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from rdkit import RDLogger  # for disabling RDKit warnings\n",
    "\n",
    "from paper.learning import predict\n",
    "from paper.learning.configure import Config\n",
    "from paper.dataset.utils import mol_from_smiles, mol_to_smiles, mol_to_ecfp, ecfp_to_string\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.error\")\n",
    "RDLogger.DisableLog('rdApp.warning')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*The 'predict_dataloader' does not have many workers which may be a bottleneck.*\")\n",
    "\n",
    "\n",
    "# Utils ------------------------------------------------------------------------\n",
    "\n",
    "def mol_to_ecfp_string(mol):\n",
    "    return ecfp_to_string(mol_to_ecfp(mol))\n",
    "\n",
    "\n",
    "def mol_from_smiles_with_exception(mol):\n",
    "    try:\n",
    "        return mol_from_smiles(mol)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Settings --------------------------------------------------------------------\n",
    "\n",
    "BASE_DIR = Path().resolve().parent\n",
    "TEST_FILE = BASE_DIR / 'data' / 'emolecules' / 'splitting' / 'test.tsv'\n",
    "OUT_FILE = BASE_DIR / 'notebooks' / 'table-2-recovery' / 'emolecules-top100-raw.tsv'\n",
    "\n",
    "# Prediction settings\n",
    "CONFIG = Config(\n",
    "    model_path= BASE_DIR / \"data\" / \"models\" / \"finetuned.ckpt\",\n",
    "    model_source_tokenizer= BASE_DIR / \"data\" / \"tokens\" / \"ECFP.model\",\n",
    "    model_target_tokenizer= BASE_DIR / \"data\" / \"tokens\" / \"SMILES.model\",\n",
    "    pred_mode=\"beam\",\n",
    "    pred_batch_size=1,\n",
    "    pred_beam_size=100,\n",
    "    pred_max_rows=1000,\n",
    ")\n",
    "CONFIG.device = \"cpu\"\n",
    "\n",
    "\n",
    "# Data preparation -------------------------------------------------------------\n",
    "\n",
    "# Load test data\n",
    "df = pd.read_csv(\n",
    "    TEST_FILE,\n",
    "    sep='\\t',\n",
    "    nrows=CONFIG.pred_max_rows if CONFIG.pred_max_rows > 0 else None\n",
    ")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['SMILES_0', 'SIGNATURE', 'SIGNATURE_MORGANS'], inplace=True)\n",
    "\n",
    "# Rename few columns for more clarity\n",
    "df = df.rename(columns={\n",
    "    'SMILES': 'Query SMILES',\n",
    "    'ECFP': 'Query ECFP',\n",
    "    'ID': 'DB ID',\n",
    "})\n",
    "\n",
    "# Append a \"Query ID\" column containing the row number for easier reference\n",
    "df['Query ID'] = range(1, len(df) + 1)\n",
    "\n",
    "# Push this column to the front\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/tduigou/miniforge3/envs/retrosig/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1000/1000 [2:25:52<00:00,  0.11it/s] \n",
      "Time taken for prediction: 0 days 02:26:01.845196\n"
     ]
    }
   ],
   "source": [
    "# Prediction -------------------------------------------------------------------\n",
    "# Tracking time for 1k molecules (with CPU computing device):\n",
    "# - top   1 using   beam search (batch= 10): 0 days 00:02:14\n",
    "# - top   1 using   beam search (batch=100): 0 days 00:01:43\n",
    "# - top  10 using   beam search (batch=  1): 0 days 00:15:55\n",
    "# - top  10 using   beam search (batch= 10): 0 days 00:17:34\n",
    "# - top 100 using   beam search (batch=  1): 0 days 02:26:01\n",
    "# - top 100 using   beam search (batch= 10): 0 days 04:10:33\n",
    "\n",
    "# We track time taken for the prediction to complete for the entire dataset\n",
    "time_before = pd.Timestamp.now()\n",
    "\n",
    "# Predict SMILES for the ECFP queries\n",
    "results = predict.run(CONFIG, query_data=df[\"Query ECFP\"].values)\n",
    "\n",
    "# Track time taken for the prediction to complete\n",
    "time_after = pd.Timestamp.now()\n",
    "time_diff = time_after - time_before\n",
    "\n",
    "# Print the time taken for the prediction to complete\n",
    "print(f\"Time taken for prediction: {time_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine results ---------------------------------------------------------------\n",
    "\n",
    "# Merge results with the original data using the \"Query ID\" column\n",
    "results = pd.merge(df, results, on=\"Query ID\", how=\"left\")\n",
    "assert results[\"Query ECFP_x\"].equals(results[\"Query ECFP_y\"])\n",
    "results.drop(columns=[\"Query ECFP_y\"], inplace=True)\n",
    "results = results.rename(columns={\"Query ECFP_x\": \"Query ECFP\"})\n",
    "\n",
    "\n",
    "# Save results -----------------------------------------------------------------\n",
    "\n",
    "results.to_csv(OUT_FILE, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Refine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import RDLogger\n",
    "\n",
    "from paper.learning.utils import (\n",
    "    mol_from_smiles,\n",
    "    mol_to_ecfp,\n",
    "    ecfp_to_string,\n",
    "    mol_to_smiles,\n",
    "    tanimoto,\n",
    ")\n",
    "\n",
    "\n",
    "# Logging ---------------------------------------------------------------------\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.error\")\n",
    "RDLogger.DisableLog(\"rdApp.warning\")\n",
    "\n",
    "\n",
    "# Utils ------------------------------------------------------------------------\n",
    "\n",
    "def mol_from_smiles_with_exception(mol):\n",
    "    try:\n",
    "        return mol_from_smiles(mol)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Load data -------------------------------------------------------------------\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"table-2-recovery\"\n",
    "FILENAME = \"emolecules-top100-raw.tsv\"\n",
    "OUTNAME = FILENAME.replace(\"-raw.tsv\", \"-refined.tsv\")\n",
    "\n",
    "df = pd.read_csv(DATA_DIR / FILENAME, sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Refine data -----------------------------------------------------------------\n",
    "\n",
    "# Let's rename the specific DB column ID to a more generic name\n",
    "df = df.rename(columns={\"EMOLECULES ID\": \"DB ID\"})\n",
    "\n",
    "# Let's recompute required information on the Query side\n",
    "df[\"Query Mol\"] = df[\"Query SMILES\"].apply(mol_from_smiles_with_exception)\n",
    "df[\"Query ECFP Object\"] = df[\"Query Mol\"].apply(mol_to_ecfp)\n",
    "\n",
    "# Quick check to see if the ECFP are the same\n",
    "assert df[\"Query ECFP\"].equals(df[\"Query ECFP Object\"].apply(ecfp_to_string))\n",
    "\n",
    "# Now let's populate back the prediction side\n",
    "df[\"Prediction Prob\"] = df[\"Prediction Log Prob\"].apply(np.exp)\n",
    "df[\"Prediction Mol\"] = df[\"Prediction SMILES\"].apply(mol_from_smiles_with_exception)\n",
    "df[\"Prediction ECFP Object\"] = df[\"Prediction Mol\"].apply(mol_to_ecfp)\n",
    "df[\"Prediction ECFP\"] = df[\"Prediction ECFP Object\"].apply(ecfp_to_string)\n",
    "\n",
    "# Now let's check for Mol validity\n",
    "df[\"SMILES Syntaxically Valid\"] = df[\"Prediction Mol\"].notnull()\n",
    "\n",
    "# Now let's check for SMILES equality\n",
    "df[\"Prediction Canonic SMILES\"] = df[\"Prediction Mol\"].apply(mol_to_smiles)\n",
    "df[\"SMILES Exact Match\"] = df[\"Query SMILES\"] == df[\"Prediction Canonic SMILES\"]\n",
    "\n",
    "# Now let's check for Tanimoto similarity\n",
    "df[\"Tanimoto\"] = df.apply(lambda x: tanimoto(x[\"Query ECFP Object\"], x[\"Prediction ECFP Object\"]), axis=1)\n",
    "df[\"Tanimoto Exact Match\"] = df[\"Tanimoto\"] == 1.0\n",
    "\n",
    "# Finally export the refined DataFrame\n",
    "cols = [\n",
    "    \"DB ID\",\n",
    "    \"Query ID\",\n",
    "    \"Query SMILES\",\n",
    "    \"Query ECFP\",\n",
    "    \"Prediction Tokens\",\n",
    "    \"Prediction Log Prob\",\n",
    "    \"Prediction Prob\",\n",
    "    \"Prediction SMILES\",\n",
    "    \"Prediction ECFP\",\n",
    "    \"Prediction Canonic SMILES\",\n",
    "    \"Tanimoto\",\n",
    "    \"SMILES Exact Match\",\n",
    "    \"Tanimoto Exact Match\",\n",
    "    \"SMILES Syntaxically Valid\",\n",
    "]\n",
    "df.to_csv(DATA_DIR / OUTNAME, sep=\"\\t\", index=False, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emolecules-top100-refined.tsv stats:\n",
      "                     Stat  Value\n",
      "0         SMILES Accuracy  0.998\n",
      "1       Tanimoto Accuracy  0.998\n",
      "2  SMILES Syntax Validity  1.000\n",
      "3     Molecule Uniqueness  1.063\n",
      "\n",
      "emolecules-top100-refined.tsv uniqueness:\n",
      "  Distinct Molecules per Query  Count\n",
      "0                            0      2\n",
      "1                            1    947\n",
      "2                            2     40\n",
      "3                            3      9\n",
      "4                            4      1\n",
      "5                            5      1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Utils -----------------------------------------------------------------------\n",
    "\n",
    "def get_summary(results: pd.DataFrame, topk=1) -> pd.DataFrame:\n",
    "    \"\"\"Get summary from the results DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : pandas.DataFrame\n",
    "        The results DataFrame.\n",
    "    topk : int, optional\n",
    "        The top-k to consider, by default 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The summary DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # First we need to get the unique sequence IDs\n",
    "    query_ids = results[\"Query ID\"].unique()\n",
    "\n",
    "    summary = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"Query ID\",\n",
    "            \"Query SMILES\",\n",
    "            \"Query ECFP\",\n",
    "            \"SMILES Exact Match\",\n",
    "            \"Tanimoto Exact Match\",\n",
    "            \"SMILES Syntaxically Valid\",\n",
    "            \"Tanimoto Exact Match Unique Count\",\n",
    "            \"Tanimoto Exact Match Unique List\",\n",
    "        ],\n",
    "        index=query_ids,\n",
    "    )\n",
    "\n",
    "    # Now for can collect results for query ID\n",
    "    for query_id in query_ids:\n",
    "\n",
    "        # Get mask corresponding to the query ID\n",
    "        query_mask = results[\"Query ID\"] == query_id\n",
    "\n",
    "        # Get subset corresponding to the top-k\n",
    "        top_query_subset = results[query_mask].nlargest(topk, \"Prediction Log Prob\")\n",
    "\n",
    "        # Get the subset from the top-k corresponding to Tanimoto exact match\n",
    "        top_query_exact_match = top_query_subset[top_query_subset[\"Tanimoto Exact Match\"]]\n",
    "\n",
    "        # Fill in the stats\n",
    "        summary.loc[query_id, \"Query ID\"] = query_id\n",
    "        summary.loc[query_id, \"Query SMILES\"] = top_query_subset.iloc[0][\"Query SMILES\"]\n",
    "        summary.loc[query_id, \"Query ECFP\"] = top_query_subset.iloc[0][\"Query ECFP\"]\n",
    "        summary.loc[query_id, \"SMILES Exact Match\"] = any(top_query_subset[\"SMILES Exact Match\"])\n",
    "        summary.loc[query_id, \"Tanimoto Exact Match\"] = any(top_query_subset[\"Tanimoto Exact Match\"])\n",
    "        summary.loc[query_id, \"SMILES Syntaxically Valid\"] = any(top_query_subset[\"SMILES Syntaxically Valid\"])\n",
    "        summary.loc[query_id, \"Tanimoto Exact Match Unique Count\"] = top_query_exact_match[\"Prediction Canonic SMILES\"].nunique()\n",
    "        summary.loc[query_id, \"Tanimoto Exact Match Unique List\"] = str(list(top_query_exact_match[\"Prediction Canonic SMILES\"].unique()))\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def get_statistics(df: pd.DataFrame, topk=1) -> pd.DataFrame:\n",
    "    \"\"\"Get statistics from the results DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The results DataFrame.\n",
    "    topk : int, optional\n",
    "        The top-k to consider, by default 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The statistics DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # First we get summary information\n",
    "    summary = get_summary(df, topk=topk)\n",
    "\n",
    "    # Now we can compute basic statistics\n",
    "    stats = summary.aggregate(\n",
    "        {\n",
    "            \"SMILES Exact Match\": [\"mean\"],\n",
    "            \"Tanimoto Exact Match\": [\"mean\"],\n",
    "            \"SMILES Syntaxically Valid\": [\"mean\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Rename columns\n",
    "    stats.columns = [\n",
    "        \"SMILES Accuracy\",\n",
    "        \"Tanimoto Accuracy\",\n",
    "        \"SMILES Syntax Validity\",\n",
    "    ]\n",
    "\n",
    "    # Transpose and set index as a \"Stat\" column\n",
    "    stats = stats.T\n",
    "    stats[\"Stat\"] = stats.index\n",
    "    stats.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Rename and reorder columns\n",
    "    stats.columns = [\"Value\", \"Stat\"]\n",
    "    stats = stats[[\"Stat\", \"Value\"]]\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def get_uniqueness(df: pd.DataFrame, topk=1) -> pd.DataFrame:\n",
    "    \"\"\"Get the number of unique molecules per query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The results DataFrame.\n",
    "    topk : int, optional\n",
    "        The top-k to consider, by default 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The unique count per query DataFrame.\n",
    "    \"\"\"\n",
    "    # First we get summary information\n",
    "    summary = get_summary(df, topk=topk)\n",
    "\n",
    "    # Get count on the number of unique SMILES per query\n",
    "    uniqueness = pd.DataFrame(summary[\"Tanimoto Exact Match Unique Count\"].value_counts().sort_index())\n",
    "    uniqueness.rename(columns={\"count\": \"Count\"}, inplace=True)\n",
    "    uniqueness[\"Distinct Molecules per Query\"] = uniqueness.index\n",
    "    uniqueness.reset_index(drop=True, inplace=True)\n",
    "    uniqueness = uniqueness.iloc[:, [1, 0]]  # reverse the order of the columns\n",
    "    \n",
    "    return uniqueness\n",
    "\n",
    "\n",
    "# Load data -------------------------------------------------------------------\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"table-2-recovery\"\n",
    "FILENAME = \"emolecules-top100-refined.tsv\"\n",
    "TOPK = 100\n",
    "\n",
    "df = pd.read_csv(DATA_DIR / FILENAME, sep=\"\\t\")\n",
    "\n",
    "# Summary ---------------------------------------------------------------------\n",
    "summary = get_summary(df, topk=TOPK)\n",
    "OUTFILE = FILENAME.replace(\"-refined.tsv\", \"-summary.tsv\")\n",
    "summary.to_csv(DATA_DIR / OUTFILE, sep=\"\\t\", index=False)\n",
    "\n",
    "# Statistics -------------------------------------------------------------------\n",
    "stats = get_statistics(df, topk=TOPK)\n",
    "OUTFILE = FILENAME.replace(\"-refined.tsv\", \"-statistics.tsv\")\n",
    "stats.to_csv(DATA_DIR / OUTFILE, sep=\"\\t\", index=False)\n",
    "\n",
    "# Uniqueness -------------------------------------------------------------------\n",
    "uniqueness = get_uniqueness(df, topk=TOPK)\n",
    "OUTFILE = FILENAME.replace(\"-refined.tsv\", \"-uniqueness.tsv\")\n",
    "uniqueness.to_csv(DATA_DIR / OUTFILE, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"{FILENAME} stats:\")\n",
    "print(stats)\n",
    "print()\n",
    "print(f\"{FILENAME} uniqueness:\")\n",
    "print(uniqueness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrosig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
